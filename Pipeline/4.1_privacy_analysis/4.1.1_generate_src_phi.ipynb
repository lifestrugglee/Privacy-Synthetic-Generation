{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6ac6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def writePickle(file_path, sth):\n",
    "    # store list in binary file so 'wb' mode\n",
    "    with open(file_path, 'wb') as fp:\n",
    "        pickle.dump(sth, fp)\n",
    "\n",
    "def loadPickle(file_path):\n",
    "    # for reading also binary mode is important\n",
    "    with open(file_path, 'rb') as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/privacy/\")\n",
    "import icd9_obj \n",
    "icd9obj = icd9_obj.ICD9_obj()\n",
    "from HIPPA import HIPAA\n",
    "hipaa = HIPAA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266eac0b-c733-4a94-865c-b1a18abb0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cae3692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 1\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device, torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4159d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 05:39:09.507259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# !python -m spacy download en_core_web_trf\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3aabba-6ed6-4f00-961a-6797318d417f",
   "metadata": {},
   "source": [
    "# 1. Generate src_phi.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c776b98-497d-41ae-8857-3fba1f48264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDir = os.path.join(\"./re_id_history/MIMIC_reid_val_record_20230704\")\n",
    "contain_dict = {}\n",
    "# load all the mapping phi pickle files\n",
    "icd9_pickle_ls = [fn for fn in os.listdir(newDir) if '.pickle' in fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3207a9-cc47-48f4-a156-2865b8eec49e",
   "metadata": {},
   "source": [
    "# Structure\n",
    "- contain_dict\n",
    "    - ICD9_Abbr (eg. ARF, UTI)\n",
    "        - Src text\n",
    "            - Re-id type\n",
    "                - List of reid elements\n",
    "                \n",
    "contain_dict = {\n",
    "\n",
    "    'ARF': {\n",
    "        '98573.txt': {\n",
    "            'date': ['January', '11/25', '11/03', '11/19',          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f9cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_re_id_hist = os.path.join(\"./re_id_history/MIMIC_reid_val_record_20230704\")\n",
    "src_phi_dict = loadPickle(os.path.join(root_re_id_hist, 'src_phi.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca3d4eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARF 98573.txt 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4815/3764280301.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mphi_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micd1_src_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mphi_keyls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# icd9_abbr_ls = list(src_phi_dict.keys())\n",
    "# for icd1_abbr in icd9_abbr_ls[2:]:\n",
    "icd1_src_dict = src_phi_dict[icd1_abbr]\n",
    "#     fls = list(icd1_src_dict.keys())\n",
    "\n",
    "for fn_idx in range(1):#len(fls)):\n",
    "    fn_key = fls[fn_idx]\n",
    "    print(icd1_abbr, fn_key, fn_idx)\n",
    "\n",
    "    phi_dict = icd1_src_dict[fn_key]\n",
    "    1/0\n",
    "    phi_keyls = phi_dict.keys()\n",
    "\n",
    "    if 'full_name' not in src_phi_dict[icd1_abbr][fn_key].keys():\n",
    "        src_phi_dict[icd1_abbr][fn_key]['full_name'] = []\n",
    "\n",
    "    if 'first_name' in phi_keyls and 'last_name' in phi_keyls:\n",
    "        content = getSrc_corpus(icd1_abbr, fn_key)\n",
    "        f_name_ls = list(set(phi_dict['first_name']))\n",
    "        l_name_ls = list(set(phi_dict['last_name']))\n",
    "\n",
    "        full_name_ls = getFullName_ls(f_name_ls, l_name_ls, content)\n",
    "\n",
    "        sent_tokenls = getTokenLsBySent(content)\n",
    "        new_full_name_ls = getFullName_byTokens(f_name_ls, l_name_ls, content, sent_tokenls)\n",
    "\n",
    "        full_name_ls.sort()\n",
    "        new_full_name_ls.sort()\n",
    "        if full_name_ls != new_full_name_ls:\n",
    "            gpt_full_name_ls = getFullName_byChatGPT(content, sent_tokenls)\n",
    "            gpt_full_name_ls = filter_gpt_name_ls(gpt_full_name_ls, f_name_ls, l_name_ls)\n",
    "            full_name_ls += new_full_name_ls\n",
    "            full_name_ls += gpt_full_name_ls\n",
    "            full_name_ls = list(set(full_name_ls))\n",
    "            full_name_ls.sort()\n",
    "        src_phi_dict[icd1_abbr][fn_key]['full_name'] += full_name_ls\n",
    "\n",
    "    # switch_full_name_phone\n",
    "    if 'full_name_phone' in phi_keyls:\n",
    "\n",
    "        if 'phone_num' not in src_phi_dict[icd1_abbr][fn_key].keys():\n",
    "            src_phi_dict[icd1_abbr][fn_key]['phone_num'] = []\n",
    "        for onepair in phi_dict['full_name_phone']:\n",
    "#                 NOT IN THE CORRECT ORDER\n",
    "            tmp_fullname, tmp_phone = re.findall(r'([\\w ]*) (\\d.*)', onepair)[0]\n",
    "            src_phi_dict[icd1_abbr][fn_key]['full_name'].append(tmp_fullname)\n",
    "            src_phi_dict[icd1_abbr][fn_key]['phone_num'].append(tmp_phone)\n",
    "        src_phi_dict[icd1_abbr][fn_key].pop('full_name_phone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f095f",
   "metadata": {},
   "source": [
    "---\n",
    "# DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFullName_byChatGPT(corpus, sent_tokenls):\n",
    "    def getResponse(question):\n",
    "        completion = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ]\n",
    "        )\n",
    "        return completion\n",
    "    \n",
    "    def partial_getResponse(token_limit = 2000):\n",
    "        chunk_token_num = 0\n",
    "        sent_ls = []\n",
    "        name_ls = []\n",
    "        for tokenls, sent  in sent_tokenls:\n",
    "            if chunk_token_num <= token_limit:\n",
    "                chunk_token_num += len(tokenls)\n",
    "                sent_ls.append(sent)\n",
    "            else:\n",
    "                part_content = '\\n'.join(sent_ls)\n",
    "                completion = getResponse(f'{prompt_instruction}\\n{part_content}')\n",
    "                name_ls += completion.choices[0].message['content'].split('\\n')\n",
    "                # reset the parameters\n",
    "                chunk_token_num = len(tokenls)\n",
    "                sent_ls = [sent]\n",
    "        return name_ls\n",
    "    \n",
    "    name_ls = []\n",
    "    prompt_instruction = 'Please list all the full name in the form of \"last name, first name\" from the following content:'\n",
    "    txt_input = f'{prompt_instruction}\\n{corpus}'\n",
    "    try:\n",
    "        completion = getResponse(txt_input)\n",
    "        name_ls += completion.choices[0].message['content'].split('\\n')\n",
    "    except:\n",
    "        try:\n",
    "            sent_ls = partial_getResponse(token_limit = 2000)\n",
    "        except:\n",
    "            sent_ls = partial_getResponse(token_limit = 1500)\n",
    "    \n",
    "    ls = []\n",
    "    for name in name_ls:\n",
    "        if ',' in name:\n",
    "            tmp_split = name.split(',')\n",
    "            if len(tmp_split) != 2: continue\n",
    "            ln, fn = tmp_split\n",
    "            if '.' in fn:\n",
    "                fn = fn.strip().split(' ')[0].strip()\n",
    "            if len(fn) > 0:\n",
    "                ls.append(f'{ln.strip()}, {fn}')\n",
    "    \n",
    "    return list(set(ls))\n",
    "\n",
    "# gpt_full_name_ls = getFullName_byChatGPT(content, sent_tokenls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32253375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter name in the src list and check the structure\n",
    "def filter_gpt_name_ls(gpt_name_ls, src_f_name_ls, src_l_name_ls):\n",
    "    tmp_ls = []\n",
    "    for gpt_name in gpt_name_ls:\n",
    "        result = re.findall(r'([A-Za-z-]*), +([A-Za-z-]*)', gpt_name)\n",
    "        if len(result) > 0 and len(result[0]) == 2:\n",
    "            l_n, f_n = result[0]\n",
    "            if f_n in src_f_name_ls and l_n in src_l_name_ls:\n",
    "                tmp_ls.append('{}, {}'.format(l_n, f_n))\n",
    "    return tmp_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenLsBySent(corpus):\n",
    "    corpus_ls = corpus.split('\\n\\n')\n",
    "    sent_token_ls = []\n",
    "    for paragraph in corpus_ls:\n",
    "        doc = nlp(paragraph.strip())\n",
    "        for sent in doc.sents:\n",
    "            sent_token_ls.append(([token.text for token in sent], sent.text) )\n",
    "    return sent_token_ls\n",
    "\n",
    "def getSrc_corpus(icd9abbr, fn):\n",
    "    with open(os.path.join(src_MIMIC_dir, dir_dict[icd9abbr], fn), 'r') as fr:\n",
    "        content = fr.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isIn(name_ls, one_sentence):# token_ls):\n",
    "    capture_ls = []\n",
    "    for name in name_ls:\n",
    "        if name in one_sentence:\n",
    "            capture_ls.append(name)\n",
    "    return capture_ls\n",
    "\n",
    "def getFullName_byTokens(first_name_ls, last_name_ls, sent_tokenls, isDebug=0):\n",
    "    ls = []\n",
    "    for tokenls, sent in sent_tokenls:\n",
    "        got_f_name_ls = isIn(first_name_ls, sent)\n",
    "        got_l_name_ls = isIn(last_name_ls, sent)\n",
    "        if len(got_f_name_ls) > 0 and len(got_l_name_ls) > 0:\n",
    "            # token level: double check the words is contained\n",
    "            if any( '-' in n for n in got_f_name_ls) or any( '-' in n for n in got_l_name_ls):\n",
    "                pass\n",
    "            else:\n",
    "                got_f_name_ls = isIn(got_f_name_ls, tokenls) \n",
    "                got_l_name_ls = isIn(got_l_name_ls, tokenls)\n",
    "            if isDebug:\n",
    "                print('getFullName_byTokens')\n",
    "                print(tokenls)\n",
    "                print(repr(sent))\n",
    "                print(got_f_name_ls, got_l_name_ls)\n",
    "                print('-'*5)\n",
    "            tmp_full_name_ls = getFullName_ls(got_f_name_ls, got_l_name_ls,\n",
    "                                              sent.replace('\\n', ' ').replace('  ', ' '))\n",
    "            if isDebug: print(f'FULL NAME -->', tmp_full_name_ls)\n",
    "            if len(tmp_full_name_ls) > 0: ls += tmp_full_name_ls\n",
    "\n",
    "    ls.sort()\n",
    "    return ls\n",
    "\n",
    "# getFullName_byTokens(first_name_ls, last_name_ls, content, isDebug=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFullName_ls(f_name_ls, l_name_ls, corpus, threshold = 3, isDebug=0):\n",
    "    f_name_lc_ls = [(corpus.find(name), len(name)) for name in f_name_ls]\n",
    "    l_name_lc_ls = [(corpus.find(name), len(name)) for name in l_name_ls]\n",
    "    \n",
    "    isGotcha = 0\n",
    "    full_name_ls = []\n",
    "    for lc_f, len_f in f_name_lc_ls:\n",
    "        for lc_l, len_l in l_name_lc_ls:\n",
    "            inRange = abs(lc_f+len_f - lc_l) <= threshold or abs(lc_l + len_l - lc_f) <= threshold\n",
    "#             print(inRange, abs(lc_f+len_f - lc_l), abs(lc_l + len_l - lc_f))\n",
    "            if inRange:\n",
    "                if lc_f < lc_l:\n",
    "                    full_name = corpus[lc_f: lc_l+len_l]\n",
    "                else:\n",
    "                    full_name = corpus[lc_l: lc_f+len_f]\n",
    "                \n",
    "                full_name = full_name.strip()\n",
    "                if ',' in full_name:\n",
    "                    f_l_ls = full_name.split(',')\n",
    "                    if len(f_l_ls) != 2: continue\n",
    "                    tmp_l, tmp_f = f_l_ls\n",
    "                    full_name = f'{tmp_l.strip()}, {tmp_f.strip()}'\n",
    "                    \n",
    "                    \n",
    "                elif ' ' in full_name:\n",
    "                    f_l_ls = full_name.strip().split(' ')\n",
    "                    if len(f_l_ls) != 2: continue\n",
    "                    tmp_f, tmp_l = f_l_ls\n",
    "                    full_name = f'{tmp_l}, {tmp_f}'\n",
    "                    \n",
    "                    \n",
    "                filter_result = [f for f in re.findall(r'((?!\\w).)', full_name) \\\n",
    "                                 if f not in [',', ' ', '-']]\n",
    "                if len(filter_result) > 0:\n",
    "                    print('-'*5)\n",
    "                    print('filter_result')\n",
    "                    print('first_name_ls = ', f_name_ls)\n",
    "                    print('last_name_ls = ', l_name_ls)\n",
    "                else:\n",
    "                    full_name_ls.append(full_name.strip())\n",
    "                    isGotcha = 1\n",
    "    return full_name_ls\n",
    "# content = '- fax results to: Name: Kent ,Monty R. Address: 2300 Deer Path Circle #207 Hurstbourne Acres KY 40220 , Glen Burnie ,56059'\n",
    "# first_name_ls = ['Monty']\n",
    "# last_name_ls = ['Kent']\n",
    "# getFullName_ls(first_name_ls, last_name_ls, content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
