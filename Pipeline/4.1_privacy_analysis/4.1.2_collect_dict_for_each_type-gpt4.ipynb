{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93ad4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def writePickle(file_path, sth):\n",
    "    # store list in binary file so 'wb' mode\n",
    "    with open(file_path, 'wb') as fp:\n",
    "        pickle.dump(sth, fp)\n",
    "\n",
    "def loadPickle(file_path):\n",
    "    # for reading also binary mode is important\n",
    "    with open(file_path, 'rb') as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/privacy/\")\n",
    "import icd9_obj \n",
    "icd9obj = icd9_obj.ICD9_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6018c6e9",
   "metadata": {},
   "source": [
    "# Steps 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab0d74-b166-4aaf-98c6-e2d02c790cd4",
   "metadata": {},
   "source": [
    "#### Structure\n",
    "- contain_dict\n",
    "    - ICD9_Abbr (eg. ARF, UTI)\n",
    "        - Src text\n",
    "            - Re-id type\n",
    "                - List of reid elements\n",
    "                \n",
    "contain_dict = {\n",
    "\n",
    "    'ARF': {\n",
    "        '98573.txt': {\n",
    "            'date': ['January', '11/25', '11/03', '11/19',          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4830479-34b7-4faa-9fb7-6050f9941a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_re_id_hist = os.path.join(\"./re_id_history/MIMIC_reid_val_record_20230704\")\n",
    "src_phi_dict = loadPickle(os.path.join(root_re_id_hist, 'src_phi.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6adb295-9210-4e37-83c7-e618aac08660",
   "metadata": {},
   "source": [
    "#### Compare w/t corresponding synthetic notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a7e4c",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741a60fd-b09d-4a6c-9b2f-0113b8978848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2Log(msg):\n",
    "    with open('collect_dict_os_src.log', 'a') as fw:\n",
    "        try:\n",
    "            fw.write(f\"{str(msg)}\\n\")\n",
    "        except:\n",
    "            fw.write(f\"{msg.encode('utf-8').strip()}\\n\")\n",
    "\n",
    "def getFullName_ls(f_name_ls, l_name_ls, corpus, threshold = 3, isDebug=0):\n",
    "    global isRecord\n",
    "    # print((f_name_ls, l_name_ls, corpus, threshold , isDebug))\n",
    "    f_name_lc_ls = [(corpus.find(name), len(name)) for name in f_name_ls]\n",
    "    l_name_lc_ls = [(corpus.find(name), len(name)) for name in l_name_ls]\n",
    "    \n",
    "    isGotcha = 0\n",
    "    full_name_ls = []\n",
    "    for lc_f, len_f in f_name_lc_ls:\n",
    "        for lc_l, len_l in l_name_lc_ls:\n",
    "            inRange = abs(lc_f+len_f - lc_l) <= threshold or abs(lc_l + len_l - lc_f) <= threshold\n",
    "#             print(inRange, abs(lc_f+len_f - lc_l), abs(lc_l + len_l - lc_f))\n",
    "            if inRange:\n",
    "                if lc_f < lc_l:\n",
    "                    full_name = corpus[lc_f: lc_l+len_l]\n",
    "                else:\n",
    "                    full_name = corpus[lc_l: lc_f+len_f]\n",
    "                \n",
    "                full_name = full_name.strip()\n",
    "                if ',' in full_name:\n",
    "                    f_l_ls = full_name.split(',')\n",
    "                    if len(f_l_ls) != 2: continue\n",
    "                    tmp_l, tmp_f = f_l_ls\n",
    "                    full_name = f'{tmp_l.strip()}, {tmp_f.strip()}'\n",
    "                    \n",
    "                    \n",
    "                elif ' ' in full_name:\n",
    "                    f_l_ls = full_name.strip().split(' ')\n",
    "                    if len(f_l_ls) != 2: continue\n",
    "                    tmp_f, tmp_l = f_l_ls\n",
    "                    full_name = f'{tmp_l}, {tmp_f}'\n",
    "\n",
    "                \n",
    "                filter_result = [f for f in re.findall(r'((?!\\w).)', full_name) \\\n",
    "                                 if f not in [',', ' ', '-', ';', ':', '(', ']']]\n",
    "                \n",
    "                if len(filter_result) > 0:\n",
    "                    # add to log\n",
    "                    isRecord = True\n",
    "                    ls = ['-'*5, isRecord, 'filter_result', 'full_name = ', full_name, 'first_name_ls = ', f_name_ls, 'last_name_ls = ', l_name_ls, 'corpus = ', corpus]\n",
    "                    for i in ls:\n",
    "                        # print(i)\n",
    "                        write2Log(i)\n",
    "                        \n",
    "                else:\n",
    "                    re_result = re.findall(r'(\\w+)', '(Peyton, Pittman')\n",
    "                    if len(re_result) == 2:\n",
    "                        full_name = ', '.join(re_result)\n",
    "                        full_name_ls.append(full_name.strip())\n",
    "                        isGotcha = 1\n",
    "\n",
    "    return full_name_ls\n",
    "\n",
    "# getFullName_ls(['Velma'], ['Walmsley'], \"The patient was intubated endotracheally, had a central line placement in his RIJ, and was living in a facility named Velma's Walmsley Living Center in Panama City Beach, Florida.\", 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae8f8a5-4f03-439c-8d9e-c3dc1380b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCollectLs(one_src_phi_dict, syn_sent_tokenls):\n",
    "    collected_ls = []\n",
    "    for phi_type, phi_val_ls in one_src_phi_dict.items():\n",
    "    \n",
    "        if phi_type == 'full_name':\n",
    "            phi_ls = one_src_phi_dict['full_name']\n",
    "            for full_name in phi_ls:\n",
    "                l_n, f_n  = full_name.split(', ')\n",
    "                for syn_token_ls, sent in syn_sent_tokenls: # checking\n",
    "                    if l_n in syn_token_ls and f_n in syn_token_ls:\n",
    "                        extracted_full_name = getFullName_byTokens([f_n], [l_n], [[syn_token_ls, sent],] )\n",
    "                        if len(extracted_full_name) == 1 and full_name == extracted_full_name[0]:\n",
    "                            collected_ls.append( (phi_type, full_name) )\n",
    "                        elif len(extracted_full_name) > 1: raise ValueError(extracted_full_name)\n",
    "        elif phi_type == 'first_name' or phi_type == 'last_name': continue\n",
    "        else:\n",
    "            for phi in phi_val_ls:\n",
    "                \n",
    "                for syn_token_ls,_ in syn_sent_tokenls:\n",
    "                    if phi in syn_token_ls:\n",
    "                        collected_ls.append( (phi_type, phi) )\n",
    "                        break\n",
    "    return collected_ls\n",
    "\n",
    "# collect_ls = getCollectLs(src_phi_dict[icd9_abbr][src_fn], syn_sent_token_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e27a5c3-9c23-43fa-858c-714a6cc87ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import spacy\n",
    "spacy.require_gpu()\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b6deb0-694d-4b86-9863-4ca4d9587833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFullName_byTokens(first_name_ls, last_name_ls, sent_tokenls, isDebug=0):\n",
    "    ls = []\n",
    "    for tokenls, sent in sent_tokenls:\n",
    "        got_f_name_ls = isIn(first_name_ls, sent)\n",
    "        got_l_name_ls = isIn(last_name_ls, sent)\n",
    "        if len(got_f_name_ls) > 0 and len(got_l_name_ls) > 0:\n",
    "            # token level: double check the words is contained\n",
    "            if any( '-' in n for n in got_f_name_ls) or any( '-' in n for n in got_l_name_ls):\n",
    "                pass\n",
    "            else:\n",
    "                got_f_name_ls = isIn(got_f_name_ls, tokenls) \n",
    "                got_l_name_ls = isIn(got_l_name_ls, tokenls)\n",
    "            if isDebug:\n",
    "                print('getFullName_byTokens')\n",
    "                print(tokenls)\n",
    "                print(repr(sent))\n",
    "                print(got_f_name_ls, got_l_name_ls)\n",
    "                print('-'*5)\n",
    "            tmp_full_name_ls = getFullName_ls(got_f_name_ls, got_l_name_ls,\n",
    "                                              sent.replace('\\n', ' ').replace('  ', ' '))\n",
    "            if isDebug: print(f'FULL NAME -->', tmp_full_name_ls)\n",
    "            if len(tmp_full_name_ls) > 0: ls += tmp_full_name_ls\n",
    "\n",
    "    ls.sort()\n",
    "    return ls\n",
    "\n",
    "# new_full_name_ls = \n",
    "# getFullName_byTokens(f_name_ls, l_name_ls, sent_tokenls, isDebug=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1fac03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_date(dateLs):\n",
    "    tmp_phi_ls = dateLs[:]\n",
    "    for idx in range(len(tmp_phi_ls)-1, -1, -1)  :\n",
    "        result = re.findall(r'\\d{1,2}[/-]\\d{1,2}', tmp_phi_ls[idx])\n",
    "        if len(result) == 0:\n",
    "            dateLs.pop(idx)\n",
    "    return dateLs\n",
    "    \n",
    "# filter name in the src list and check the structure\n",
    "def filter_gpt_name_ls(gpt_name_ls, src_f_name_ls, src_l_name_ls):\n",
    "    tmp_ls = []\n",
    "    for gpt_name in gpt_name_ls:\n",
    "        result = re.findall(r'([A-Za-z-]*), +([A-Za-z-]*)', gpt_name)\n",
    "        if len(result) > 0 and len(result[0]) == 2:\n",
    "            l_n, f_n = result[0]\n",
    "            if f_n in src_f_name_ls and l_n in src_l_name_ls:\n",
    "                tmp_ls.append('{}, {}'.format(l_n, f_n))\n",
    "    return tmp_ls\n",
    "\n",
    "def getTokenLsBySent(corpus):\n",
    "    corpus_ls = corpus.split('\\n\\n')\n",
    "    sent_token_ls = []\n",
    "    for paragraph in corpus_ls:\n",
    "        doc = nlp(paragraph.strip())\n",
    "        for sent in doc.sents:\n",
    "            sent_token_ls.append(([token.text for token in sent], sent.text) )\n",
    "    return sent_token_ls\n",
    "\n",
    "def getSrc_corpus(icd9abbr, fn):\n",
    "    with open(os.path.join(src_MIMIC_dir, ICD9_ABBR2FULL[icd9abbr], fn), 'r') as fr:\n",
    "        content = fr.read()\n",
    "    return content\n",
    "\n",
    "def isIn(name_ls, one_sentence):# token_ls):\n",
    "    capture_ls = []\n",
    "    for name in name_ls:\n",
    "        if name in one_sentence:\n",
    "            capture_ls.append(name)\n",
    "    return capture_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0686b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a4854c7",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b84421-7586-4a91-b85b-313df56d52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'/home/privacy/data/MIMIC3'\n",
    "\n",
    "data_type_ls = ['reid', 'deid']\n",
    "data_type = data_type_ls[0]\n",
    "\n",
    "prompt_dir = os.path.join( root, f'src_{data_type}', 'output_csv_4k_n')\n",
    "\n",
    "generation_ls = ['one_shot_src']#, 'keyword']\n",
    "# generation_type = 'one_shot'\n",
    "TOT_NUM = 9817\n",
    "\n",
    "# model_ls = [ 'gpt-35-turbo-a0301', 'gpt-4-0613', 'Mistral7b']\n",
    "model_ls = [ 'Mistral7b','gpt-35-turbo-a0301','gpt-4-0613', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1991a8c9-1e16-4f10-afbb-734305f2e499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 1063/1063 [00:00<00:00, 546792.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 999/999 [00:00<00:00, 561075.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1081/1081 [00:00<00:00, 556119.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 3447/3447 [00:00<00:00, 559944.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 989/989 [00:00<00:00, 566457.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 410/410 [00:00<00:00, 536389.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1009/1009 [00:00<00:00, 559721.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 798/798 [00:00<00:00, 568646.72it/s]\n"
     ]
    }
   ],
   "source": [
    "isRecord = False\n",
    "for data_type in data_type_ls:\n",
    "    prompt_dir = os.path.join( root, f'src_{data_type}', 'output_csv_4k_n')\n",
    "    for generation_type in generation_ls:\n",
    "        for model_type in model_ls:\n",
    "            task_name = f'{data_type} {generation_type} {model_type}'\n",
    "            for icd9_idx in range(len(icd9obj.ICD9_ABBR_LS)):\n",
    "                icd9_abbr = icd9obj.ICD9_ABBR_LS[icd9_idx]\n",
    "\n",
    "                output_dir = os.path.join(prompt_dir, generation_type, model_type, icd9_abbr)\n",
    "                if os.path.isdir(output_dir): \n",
    "                    fls = glob(os.path.join(output_dir, '*.txt'))\n",
    "                    collect_dict = {}\n",
    "                    collected_pickle_fp = os.path.join(prompt_dir, generation_type, model_type, f'{icd9_abbr}_collect_dict.pickle')\n",
    "                    if os.path.exists(collected_pickle_fp): collect_dict = loadPickle(collected_pickle_fp)\n",
    "                    for fidx in tqdm(range(len(fls))):\n",
    "                        fp = fls[fidx]\n",
    "                        fn = os.path.basename(fp)\n",
    "                        if fn in collect_dict.keys(): continue\n",
    "                        src_fn = fn.replace('syn_', '')\n",
    "                        with open(fp, 'r', encoding='utf-8') as fr:\n",
    "                            syn_content = fr.read()\n",
    "                        syn_sent_token_ls = getTokenLsBySent(syn_content)\n",
    "                        collect_ls = getCollectLs(src_phi_dict[icd9_abbr][src_fn], syn_sent_token_ls)\n",
    "                        if isRecord:\n",
    "                            write2Log(f'Current Task --> {task_name} --------------------------------')\n",
    "                            write2Log(f'Error in --> {icd9_abbr} {fn} {fidx}')\n",
    "                            write2Log('='*20)\n",
    "                            isRecord = False\n",
    "                            \n",
    "                        collect_dict[fn] = collect_ls\n",
    "                        if fidx%30 == 0: writePickle(collected_pickle_fp, collect_dict)\n",
    "                    \n",
    "                    writePickle(collected_pickle_fp, collect_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
